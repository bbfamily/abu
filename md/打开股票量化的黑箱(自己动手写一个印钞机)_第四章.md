# æ‰“å¼€è‚¡ç¥¨é‡åŒ–çš„é»‘ç®±(è‡ªå·±åŠ¨æ‰‹å†™ä¸€ä¸ªå°é’æœº) ç¬¬å››ç« 

### ä½œè€…ï¼šé˜¿å¸ƒğŸ¶

### æœªç»æœ¬äººå…è®¸ç¦æ­¢è½¬è½½
_____
##  éå‡è¡¡èƒœè´Ÿæ”¶ç›Šå¸¦æ¥çš„å¿…ç„¶éå‡è¡¡èƒœè´Ÿæ¯”ä¾‹ï¼Œç›®æ ‡ç”±å› å­çš„èƒ½åŠ›è§£å†³ä¸€éƒ¨åˆ†ï¼Œæ¨¡å¼è¯†åˆ«æå‡å…³é”®çš„ä¸€éƒ¨åˆ†
ä¸Šä¸€ç« ä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ–¹æ³•ï¼Œæƒ³è¦æå–ç‰¹å¾ï¼ŒæŒ‡å¯¼äº¤æ˜“ï¼Œæé«˜èƒœç‡ï¼Œä½†æ˜¯å‘ç°ï¼Œé™¤äº†æœ€åé‚£ç§æŠŠäº¤æ˜“ç»“æœåˆ†æˆ100ä»½çš„æ–¹å¼å¤–ï¼Œå…¶å®ƒæœºå™¨å­¦ä¹ æ–¹æ³•åŸºæœ¬éƒ½æ˜¯ççŒœï¼Œæ˜¯ä¸æ˜¯ä½¿ç”¨æ·±åº¦å­¦ä¹ å°±èƒ½è§£å†³é—®é¢˜å‘¢ï¼Ÿæœ¬ç« ä¸»è¦é€šè¿‡ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹alex_net,  ä¸google_lenetå¯¹è‚¡ç¥¨è¿›è¡Œæ¨¡å¼è¯†åˆ«

### åŠ è½½ç¼“å­˜äº¤æ˜“æ•°æ®
	# ä»ä¹‹å‰è·‘çš„ç»“æœhdf5ä¸­åŠ è½½ç¼“å­˜
	from MlFiterDegPd import MlFiterDegPdClass
	orders_pd_train_snap = ZCommonUtil.load_hdf5('orders_pd_train_snap', 'orders_pd_train_snap')
	orders_pd_test_snap = ZCommonUtil.load_hdf5('orders_pd_test_snap', 'orders_pd_test_snap')
	orders_pd_test_snap.shape
	deg = MlFiterDegPdClass(orderPd=orders_pd_train_snap)
	deg.x[:5], deg.y[:5]
		# out
		(array([[  0.13997608,   0.07045403,   0.06829068],
		        [ -0.40946745,  -0.38829941,   0.75027609],
		        [ 11.84144398,  -0.84690618,   2.73882144],
		        [-17.26610011,  -3.57896598,  -3.86127002],
		        [ -9.14670563,   4.14514014,   2.85483688]]),
		 array([ 0.,  0.,  0.,  0.,  1.]))

## é¦–å…ˆä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œï¼Œæ˜æ˜¾ä¹Ÿæ˜¯ä¸è¡Œ

	from MlFiterTensorFlow import MnnTF
	from sklearn.cross_validation import KFold

	kf = KFold(len(deg.y), n_folds=10, shuffle=True)
	for i, (train_index, test_index) in enumerate(kf):
	    x_train, x_test = deg.x[train_index], deg.x[test_index]
	    y_train, y_test = deg.y[train_index], deg.y[test_index]
	    mnn = MnnTF(x_train, y_train, x_test, y_test, n_hidden_1=10, n_hidden_2=10, batch_size=len(deg.x)/2,
	                 learning_rate=0.01, training_epochs=10000, display_step=1000)
	    ac = mnn.fit()
	    break # only once
		# out
		Epoch: 0001 cost= 3.815575361
		Epoch: 1001 cost= 0.691299200
		Epoch: 2001 cost= 0.695304811
		Epoch: 3001 cost= 0.691083640
		Epoch: 4001 cost= 0.690261781
		Epoch: 5001 cost= 0.690387607
		Epoch: 6001 cost= 0.691023856
		Epoch: 7001 cost= 0.689246446
		Epoch: 8001 cost= 0.690071583
		Epoch: 9001 cost= 0.690521151
		Optimization Finished!
		Accuracy:0.504002

___
    orders_pd_train_snap.ix[0].snap
        # out
        '/Users/Bailey/Desktop/my_work/abu/data/save_png/2016-10-09/2016_10_09_12_06_59_042764_4241_lyQvysYoAwVoFylreOwxNXNXvvncdyyjDEjSORFMEUAfJBpLBHjXFbwQBUoZRtkO.png'
     
ä¹‹å‰æŠŠæ‰€æœ‰äº¤æ˜“å‰çš„snapéƒ½ä¿ç•™äº†(snapä¸ºäº¤æ˜“å‰60æ—¥çš„kå›¾)ï¼Œè¿™å›ä¸è‡ªå·±ä¼ å…¥ç‰¹å¾ï¼Œç›´æ¥ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œè‡ªå·±å­¦ä¹ ç‰¹å¾


![Snip20161014_5.png](http://upload-images.jianshu.io/upload_images/3136804-e408467ee8039d8d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## é¦–å…ˆä½¿ç”¨TensorFlowçš„é«˜çº§api tflearnæ¥å®ç°alex_netçš„å·ç§¯ç¥ç»ç½‘ç»œ

	# å‡†å¤‡å·¥ä½œ
	import TrainValSplit
	import os
	import shutil

	# æŠŠç»“æœcut 10ä»½
	def cut_order_profit_classes(orders_pd, test=False, n_classes=10):
	    orders_pd.profit_cg.fillna(0, inplace=True)
	    order_has_ret = orders_pd[(orders_pd.result <> 0)]
	    order_has_ret['class'] = pd.qcut(order_has_ret.profit_cg, n_classes, labels=range(0, n_classes))
	    order_has_ret['class'] = order_has_ret['class'].astype(int)
	    snap_pd = order_has_ret.filter(['snap', 'class'])
	    img_root_folder = os.path.dirname(snap_pd.ix[0].snap)
	    img_root_folder = img_root_folder + '/'
	    if test:
	        img_root_folder += 'test/'  
	    return snap_pd, img_root_folder

___
    # cutè®­ç»ƒé›†
    snap_pd, img_root_train_folder = cut_order_profit_classes(orders_pd_train_snap, test=False)
    img_root_train_folder
        # out
        '/Users/Bailey/Desktop/my_work/abu/data/save_png/2016-10-09/'

____
    # cutæµ‹è¯•é›†
    snap_pd_test, img_root_test_folder = cut_order_profit_classes(orders_pd_test_snap, test=True)
    img_root_test_folder
        # out
        '/Users/Bailey/Desktop/my_work/abu/data/save_png/2016-10-09/test/'

____

	# åšå­æ–‡ä»¶å¤¹æ”¾åˆ†ç±»å›¾åªæ˜¯ä¸ºäº†ä½¿ç”¨tflearnçš„build_image_dataset_from_diræ–¹ä¾¿
	def make_sub_dir_mv(snap_pd, img_root_folder):
	    target_dir = img_root_folder 
	    map(lambda cls: os.makedirs(target_dir + str(cls) + '/') 
	        if not os.path.exists(target_dir + str(cls) + '/') else 1, np.arange(0, 10))
	    
	    for ind in np.arange(0, len(snap_pd)):
	        path = snap_pd.ix[ind]['snap']
	        cls  = snap_pd.ix[ind]['class']
	        
	        target_path = target_dir + str(cls) + '/' + os.path.basename(path)
	        if os.path.exists(target_path):
	            continue
	        
	        shutil.move(path, target_path)
	    snap_pd['snap'] = snap_pd.apply(lambda snap: str(snap['class']) + '/' + os.path.basename(snap.snap), axis=1)

___

    # ç§»åŠ¨è®­ç»ƒé›†snap
    make_sub_dir_mv(snap_pd, img_root_train_folder)
    # ç§»åŠ¨æµ‹è¯•é›†snap
    make_sub_dir_mv(snap_pd_test, img_root_test_folder)
    snap_pd.head()



![Snip20161020_26.png](http://upload-images.jianshu.io/upload_images/3136804-7ee9df4b9b8ee5d1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


	# å°†è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„pngéƒ½è½¬æ¢ä¸ºrgbçš„jpeg
	import ImgStdHelper
	to = img_root_train_folder
	for ind in np.arange(0, 10):
	    std_dir = to + str(ind) + "/"
	    ImgStdHelper.std_img_from_root_dir(std_dir, 'png')
	to = img_root_test_folder
	for ind in np.arange(0, 10):
	    std_dir = to + str(ind) + "/"
	    ImgStdHelper.std_img_from_root_dir(std_dir, 'png')

    snap_pd.snap = snap_pd.snap.apply(lambda snap: snap[:-4] + '.jpeg')
    snap_pd_test.snap = snap_pd_test.snap.apply(lambda snap: snap[:-4] + '.jpeg')

### è·å–è®­ç»ƒæ•°æ®
	from tflearn.data_utils import build_image_dataset_from_dir

	# è·å–è®­ç»ƒæ•°æ®
	dataset_file = ZEnv.g_project_root + '/Caffe/gen/stock_tensor.pkl'
	one_hot=True, 
	resize_pics=(227, 227)
	x, y = build_image_dataset_from_dir(img_root_train_folder,
	                             dataset_file=dataset_file,
	                             resize=resize_pics,
	                             filetypes=['.jpg', '.jpeg'],
	                             convert_gray=False,
	                             shuffle_data=True,
	                             categorical_Y=one_hot)

### ä½¿ç”¨tflearå¼€å§‹è®­ç»ƒ
	import tflearn
	from tflearn.layers.core import input_data, dropout, fully_connected
	from tflearn.layers.conv import conv_2d, max_pool_2d
	from tflearn.layers.normalization import local_response_normalization
	from tflearn.layers.estimator import regression
	network = input_data(shape=[None, 227, 227, 3])
	network = conv_2d(network, 96, 11, strides=4, activation='relu')
	network = max_pool_2d(network, 3, strides=2)
	network = local_response_normalization(network)
	network = conv_2d(network, 256, 5, activation='relu')
	network = max_pool_2d(network, 3, strides=2)
	network = local_response_normalization(network)
	network = conv_2d(network, 384, 3, activation='relu')
	network = conv_2d(network, 384, 3, activation='relu')
	network = conv_2d(network, 256, 3, activation='relu')
	network = max_pool_2d(network, 3, strides=2)
	network = local_response_normalization(network)
	network = fully_connected(network, 4096, activation='tanh')
	network = dropout(network, 0.5)
	network = fully_connected(network, 4096, activation='tanh')
	network = dropout(network, 0.5)
	network = fully_connected(network, 10, activation='softmax')
	network = regression(network, optimizer='momentum',
	                     loss='categorical_crossentropy',
	                     learning_rate=0.001)
	model = tflearn.DNN(network, checkpoint_path='model_alexnet',
	                    max_checkpoints=1, tensorboard_verbose=2)
	model.fit(x, y, n_epoch=1000, validation_set=0.1, shuffle=True,
	          show_metric=True, batch_size=64, snapshot_step=200,
	          snapshot_epoch=False, run_id='alexnet_stock')

____

	# æŠ½å–100å¼ ä½œä¸ºæµ‹è¯•ï¼Œæ¯ä¸ªclassæŠ½å–10å¼ 
	fr = img_root_test_folder
	to = img_root_test_folder + 'choice_test/'

	for ind in np.arange(0, 10):
	    ff = fr + str(ind) + "/*.jpeg"
	    imglist = glob.glob(ff) 
	    imglist = np.random.choice(imglist, 10, replace=False)
	    for img in imglist:
	        img_to = to + str(ind) + "/" + os.path.basename(img)
	        ZCommonUtil.ensure_dir(img_to)
	        shutil.copy(img, img_to)
	        
	# åŠ è½½æµ‹è¯•æ•°æ®        
	dataset_file_test = ZEnv.g_project_root + '/Caffe/gen/stock_tensor_test.pkl'
	print(dataset_file_test)
	one_hot=True, 
	resize_pics=(227, 227)
	test_folder = to
	x_test, y_test = build_image_dataset_from_dir(test_folder,
	                             dataset_file=dataset_file_test,
	                             resize=resize_pics,
	                             filetypes=['.jpg', '.jpeg', '.png'],
	                             convert_gray=False,
	                             shuffle_data=True,
	                             categorical_Y=one_hot)

____
     x_test.shape, y_test.shape
         # out
        ((100, 227, 227, 3), (100, 10))


____

	test_ret = model.predict(x_test)
	test_cnt = len(test_ret)
	rt_cnt = 0
	for pred_y, real_y in zip(test_ret, y_test):
	    real_y = np.argmax(real_y)
	    f = np.argmax(pred_y)
	    if f == real_y:
	        rt_cnt += 1
	        continue
	        
	    pred_y[f] = 0
	    t = np.argmax(pred_y)
	    if t == real_y:
	        rt_cnt += 1
	        continue
	        
	    pred_y[t] = 0
	    ttt = np.argmax(pred_y)
	    if ttt == real_y:
	        rt_cnt += 1
	        continue
	rt_cnt, test_cnt
        # out
        (58, 100)

## top3çš„å‡†ç¡®ç‡è¾¾åˆ° 58%ï¼Œç¨ä¸ºåŠ å·¥ä¸€ä¸‹å°±å¯ä»¥æ”¾åˆ°ç¨‹åºé‡Œä½œä¸ºä¼˜åŒ–å™¨äº†ï¼Œä½¿ç”¨æ–¹å¼ç±»ä¼¼:å•å­ä¹°å…¥ä¹‹å‰å¯¹below 3å’Œtop3è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœåœ¨below3ä¸­ä¸”ä¸top3åœ¨ä¸­è¿›è¡Œæ‹¦æˆªï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æœ‰æ›´å¤šå˜ç§ï¼Œå…³äºè¿™æ–¹é¢çš„å®ä¾‹å°†ä¼šåœ¨åç»­ç« èŠ‚hmm-gmmä¸­æ¼”ç¤ºï¼Œæ›´ä¼šå»¶ä¼¸åˆ°è£åˆ¤æœºåˆ¶

______

## æ¥ä¸‹æ¥ä½¿ç”¨caffeè¿›è¡Œè®­ç»ƒï¼Œä¼˜åŒ–
## ä½¿ç”¨google_lenetçœ‹çœ‹èƒ½ä¸èƒ½æœ‰å†æ¬¡æå‡

	def caffe_train_sh(snap_pd, img_root_folder):
	    train_path = ZEnv.g_project_root + '/caffe/gen/train.txt'
	    ZCommonUtil.ensure_dir(train_path)
	    snap_pd.to_csv(train_path, sep=' ', header=None, index=False)
	    TrainValSplit.train_val_split(train_path, n_folds=10)
	    lmdb = ZEnv.g_project_root + '/Caffe/sh/Lmdb.sh'
	    out_put_dir = ZEnv.g_project_root + '/Caffe/gen'
	    sh_cmd = '{} ${} ${}'.format(lmdb, img_root_folder, out_put_dir) 
	    print(sh_cmd)
	    os.system(sh_cmd)
	    return sh_cmd
  ### ç”Ÿæˆè®­ç»ƒæµ‹è¯•é›†ï¼Œä¹‹åç”Ÿæˆlmdb åŠ mean pb

    sh_cmd = caffe_train_sh(snap_pd, img_root_train_folder)
        # out 
        /Users/Bailey/Desktop/my_work/abu/Caffe/sh/Lmdb.sh $/Users/Bailey/Desktop/my_work/abu/data/save_png/2016-10-09/ $/Users/Bailey/Desktop/my_work/abu/Caffe/gen


### å…³äºå…¶å®ƒé…ç½®ï¼Œè¯·è‡ªå·±æŸ¥çœ‹ä»£ç pbæ–‡ä»¶ï¼Œè®­ç»ƒå®Œæ¨¡å‹ä¹‹åå…ˆæ‹¿ä¸€ä¸ªæµ‹è¯•çœ‹çœ‹æ•ˆæœ

    path = img_root_test_folder + snap_pd_test.ix[0].snap
    real_classes = snap_pd_test.ix[0]['class']
    real_classes
        # out
         1

### åŠ è½½è®­ç»ƒå¥½äº†çš„æ¨¡å‹

	import caffe
	caffe.set_mode_cpu()

	image = caffe.io.load_image(path)
	model_def = ZEnv.g_project_root + '/Caffe/pb/deploy.prototxt' 
	model_weights = ZEnv.g_project_root + '/Caffe/gen/stock_judge_train_iter_6000.caffemodel'
	model_mean_file = ZEnv.g_project_root + '/Caffe/gen/mean.binaryproto'

	net = caffe.Net(model_def, model_weights, caffe.TEST)  

	mean_blob = caffe.proto.caffe_pb2.BlobProto()
	mean_blob.ParseFromString(open(model_mean_file, 'rb').read())
	mean_npy = caffe.io.blobproto_to_array(mean_blob)
	mu = mean_npy.mean(2).mean(2)[0]
	print('mu = {}'.format(mu))
	transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})
	transformer.set_transpose('data', (2,0,1))  
	transformer.set_mean('data', mu)           
	transformer.set_raw_scale('data', 255)     
	transformer.set_channel_swap('data', (2,1,0))  

____

    transformed_image = transformer.preprocess('data', image)
    net.blobs['data'].data[...] = transformed_image
    output = net.forward()
    output_prob = output['prob'][0]
    print('demo classes is {}'.format(classes))
    print('predicted class is:', output_prob.argmax())
    print('Top3 is:', output_prob.argsort()[::-1][:3])
        # out
        demo classes is 1
        ('predicted class is:', 7)
        ('Top3 is:', array([7, 3, 1]))


å¦‚ä¸‹ï¼Œ æµ‹è¯•æ•°æ®é›†çš„å¤´100ä¸ªä½œä¸ºæµ‹è¯•
è®¡ç®—top3ä¸top5çš„å‡†ç¡®ç‡
top3: 54%
top5: 63%

	top3 = 0
	top5 = 0
	for ind in np.arange(0, 100):
	    path = img_root_test_folder + snap_pd_test.ix[ind].snap
	    classes = snap_pd_test.ix[ind]['class']
	    
	    image = caffe.io.load_image(path)
	    net.blobs['data'].data[...] = transformed_image
	    output = net.forward()
	    output_prob = output['prob'][0]
	    if classes in output_prob.argsort()[::-1][:3]:
	        top3 += 1
	        top5 += 1
	    elif classes in output_prob.argsort()[::-1][:5]:
	        top5 += 1
	top3, top5
        # out
        (54, 63)

### ä½¿ç”¨æ·±åº¦å­¦ä¹ ç¡®å®å¯¹æ•´ä¸ªæ¨¡å¼è¯†åˆ«ç›¸æ¯”å…¶å®ƒæœºå™¨å­¦ä¹ æ–¹æ³•æœ‰äº†å¾ˆå¤§çš„é£è·ƒï¼Œæœ‰äº†è¿™ä¸ªç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼Œå°±å¯ä»¥æ€»ç»“å‡ºæ–°çš„äº¤æ˜“æ‹¦æˆªèƒ½åŠ›ï¼Œè¿›ä¸€æ­¥æå‡èƒœç‡ï¼Œå‡æƒ³ä¸€ä¸‹ä½ çš„æ•´ä¸ªæ¨¡å‹èƒ½åŠ›èƒ½æœ‰60çš„èƒœç‡è€Œä¸”æ¯æ¬¡èµ¢çš„è¿˜æ¯”è¾“çš„å¤šï¼Œé‚£å®ƒæ˜¯ä¸æ˜¯å°±å¯ä»¥ç§°ä¸ºå°é’æœºå‘¢ï¼Œå½“ç„¶äº†è¿˜æœ‰å¾ˆå¤šå…¶å®ƒå› ç´ å½±å“äº†å°é’æœºçš„å…·ä½“å·¥ä½œï¼Œè¿™é‡Œæ— æ³•ä¸€ä¸€é˜è¿°ï¼Œæœ‰å…´è¶£çš„å¯ä»¥åŠ æˆ‘çš„å¾®ä¿¡ä¸€èµ·è®¨è®ºï¼


![Snip20161021_50.png](http://upload-images.jianshu.io/upload_images/3136804-87e7c4be5fd30fff.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

_______
## æ„Ÿè°¢ğŸ™æ‚¨èƒ½æœ‰è€å¿ƒçœ‹åˆ°è¿™é‡Œ
## å¦‚æœæœ‰ä»€ä¹ˆé—®é¢˜å¯ä»¥åŠ é˜¿å¸ƒçš„å¾®ä¿¡ 
## å¾®ä¿¡å·ï¼šaaaabbbuu


![mmexport1475383814280.jpg](http://upload-images.jianshu.io/upload_images/3136804-a9f26206d66f9a9f.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)